
---

## ğŸ§ª ExercÃ­cio 1 â€” ClassificaÃ§Ã£o Multiclasse (Wine)
- **Camadas:** 2 ocultas (32 neurÃ´nios, ReLU)
- **SaÃ­da:** 3 neurÃ´nios (Softmax)
- **Loss:** `categorical_crossentropy`
- **Otimizador:** `Adam`

### ğŸ“Š Resultados
| Modelo | AcurÃ¡cia | ObservaÃ§Ãµes |
|--------|-----------|--------------|
| Rede Neural (Keras) | 0.97 | Aprendizado estÃ¡vel apÃ³s 20 Ã©pocas |
| RandomForest | 0.99 | Melhor desempenho geral e menor tempo de treino |

**ConclusÃ£o:** Modelos baseados em Ã¡rvore ainda sÃ£o mais eficazes em dados tabulares pequenos.

---

## ğŸ  ExercÃ­cio 2 â€” RegressÃ£o (California Housing)
- **Camadas:** 3 ocultas (64, 32, 16 neurÃ´nios â€“ ReLU)
- **SaÃ­da:** 1 neurÃ´nio (Linear)
- **Loss:** `mse`
- **Otimizador:** `Adam`

### ğŸ“ˆ Resultados
| Modelo | RMSE | MAE | ObservaÃ§Ãµes |
|--------|------|-----|--------------|
| Rede Neural (Keras) | 0.58 | 0.45 | Boa generalizaÃ§Ã£o apÃ³s normalizaÃ§Ã£o |
| RandomForest | 0.47 | 0.36 | Melhora o erro em ~15% |

**ConclusÃ£o:** Para dados estruturados/tabulares, RandomForest continua mais eficiente, mas a rede neural Ã© competitiva com bom ajuste e normalizaÃ§Ã£o.

---

## âš™ï¸ Como Executar
1. Abrir os notebooks no **Google Colab**.
2. Rodar todas as cÃ©lulas (os datasets sÃ£o baixados automaticamente).
3. Conferir grÃ¡ficos e mÃ©tricas no final de cada notebook.

---

## ğŸ‘©â€ğŸ’» Tecnologias Utilizadas
- Python 3.10+
- TensorFlow / Keras
- Scikit-learn
- Matplotlib / Seaborn

---

## ğŸ‘¤ Autores
- Henrique Maciel â€” RM556480
- Gabriela Moguinho GonÃ§alves â€” RM556143
- Marina Christina Fernandes Rodrigues â€” RM554773
